{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# タスク 3: 質問応答に Amazon Bedrock を使用する\n",
    "\n",
    "このノートブックでは、関連する完全なコンテキストを含むリクエストをモデルに送信し、応答が返されるのを待つことで、クエリに対する情報の応答をAmazon Bedrockを通じて Anthropic Claude モデルから得る方法を学習します。これにより、事前にドキュメントを準備してインデックスを作成することなく、モデルが質問に対して事実に基づいた応答を返すという課題に対処します。\n",
    "\n",
    "このノートブックは、**Retrieval-Augmented Generation (RAG)** が行うことをシミュレートしますが、実際には RAG を使用しません。このアプローチは、短いドキュメントまたはシングルトンアプリケーションで機能します。モデルに送信されるプロンプトに収まらないような大規模なエンタープライズドキュメントを使用するエンタープライズレベルの質問応答には拡張できない可能性があります。\n",
    "\n",
    "**質問応答 (QA)** は、自然言語で提示された事実に基づくクエリに対する応答を抽出する重要なタスクです。通常、QA システムは、構造化データまたは非構造化データを含むナレッジ ベースに対してクエリを処理し、正確な情報を含む応答を生成します。高い精度を確保することは、特にエンタープライズ ユース ケースにおいて、有用で信頼性が高く、信頼できる質問応答システムを開発する上で重要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シナリオ\n",
    "\n",
    "AnyCompany で、同社が製造する特定の車両モデルのタイヤ交換に関する情報を提供するよう質問応答モデルに求める状況をモデル化してみます。まず、「ゼロショット」アプローチを使用してモデルにクエリを実行し、トレーニングデータのみに基づいて適切な回答を提供できるかどうかを確認します。\n",
    "\n",
    "ただし、偽の車両モデルを試して同様の応答が得られた場合、モデルがより一般的な回答を「幻覚」しているように見えることがわかります。これは、各モデルのタイヤの詳細を提供するために、Example Company の実際の車両マニュアルを使用してモデルのトレーニングを拡張する必要があることを意味します。\n",
    "\n",
    "このラボでは、外部データなしでこのような「検索拡張生成」(RAG) アプローチをシミュレートします。AnyCompany AC8 車両のタイヤ交換方法を説明した詳細なマニュアルの抜粋を提供します。このコンテキスト内のサンプル コンテンツを活用して、モデルがカスタマイズされた正確な回答を提供できるかどうかをテストします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: 環境のセットアップ\n",
    "\n",
    "このタスクでは、環境をセットアップします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ignore warnings and create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タスク 3.2: モデルの知識を使用した Q&A\n",
    "このセクションでは、Bedrock サービスによって提供されるモデルを使用して、トレーニングフェーズ中に獲得した知識に基づいて質問に答えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このタスクでは、Amazon Bedrock クライアントのinvoke_model() メソッドを使用します。このメソッドを使用するために必要な必須パラメータは、Amazon Bedrock モデル ARN を表す modelId と、タスクのプロンプトである body です。\n",
    "\n",
    "body プロンプトは、選択した基盤モデル プロバイダーに応じて変わります。これについては、以下で詳しく説明します。\n",
    "\n",
    "```json\n",
    "{\n",
    "   modelId= model_id,\n",
    "   contentType= \"application/json\",\n",
    "   accept= \"application/json\",\n",
    "   body=body\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Bedrock サービスによって提供されるモデルを使用して、トレーニング フェーズ中に得られた知識に基づいて質問に答えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"あなたは役に立つアシスタントです。質問には簡潔に答えてください。答えに自信がない場合は、「わかりません」と言ってください。\n",
    "\n",
    "Question: AnyCompany AC8 のパンクしたタイヤを修理するにはどうすればいいですか？\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** While running the code in upcoming tasks, you might observe *ThrottlingException* messages and retry attempts. Your code includes robust error handling that will automatically retry failed requests with exponential backoff. This is normal behavior when working with service quotas and demonstrates how production-ready applications should handle API limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タスク3.3: JSON本体を渡してモデルを呼び出し、レスポンスを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "# Model configuration\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "# Body parameters for Llama model\n",
    "body = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.9,\n",
    "    \"messages\": [\n",
    "     {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt_data}],\n",
    "     }\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Retry configuration\n",
    "max_retries = 5\n",
    "retry_delay = 10  # seconds\n",
    "\n",
    "def invoke_model_with_retry(bedrock_client, modelId, body, contentType, accept, max_retries, retry_delay):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_client.invoke_model(\n",
    "                modelId=modelId,\n",
    "                body=json.dumps(body),\n",
    "                contentType=contentType,\n",
    "                accept=accept\n",
    "            )\n",
    "            \n",
    "            response_body = json.loads(response.get('body').read())\n",
    "            return response_body[\"content\"][0][\"text\"]\n",
    "\n",
    "        except ClientError as error:\n",
    "            if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources:\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "                raise\n",
    "\n",
    "            elif error.response['Error']['Code'] in ['ThrottlingException', 'ServiceUnavailableException']:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Service capacity reached. Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    retry_delay *= 2  # Exponential backoff\n",
    "                else:\n",
    "                    print(\"Max retries reached. Unable to invoke the model.\")\n",
    "                    raise\n",
    "\n",
    "            else:\n",
    "                print(f\"An error occurred: {error}\")\n",
    "                raise\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            raise\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    result = invoke_model_with_retry(bedrock_client, modelId, body, contentType, accept, max_retries, retry_delay)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to invoke the model after retries: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "モデルは AnyCompany AC8 に適した回答は返せません。これは、モデルがトレーニングされたデータに AnyCompany AC8 のデータが無いためです。\n",
    "\n",
    "この問題の別の例は、Amazon Tirana など、完全に偽の車のブランドとモデルに同じ質問をしてみることでわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Usage\n",
    "prompt_data = \"Amazon Tirana のパンクしたタイヤを修理するにはどうすればいいですか?\"\n",
    "\n",
    "\n",
    "\n",
    "def invoke_model_with_retry(prompt_data, max_retries=5, initial_delay=10):\n",
    "    modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    \n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"messages\": [\n",
    "         {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": prompt_data}],\n",
    "         }\n",
    "        ],\n",
    "    })\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_client.invoke_model(\n",
    "                body=body, \n",
    "                modelId=modelId, \n",
    "                accept=accept, \n",
    "                contentType=contentType\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "            return response_body[\"content\"][0][\"text\"]\n",
    "            \n",
    "        except ClientError as error:\n",
    "            error_code = error.response['Error']['Code']\n",
    "            \n",
    "            if error_code == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources:\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "                raise\n",
    "                \n",
    "            elif error_code in ['ThrottlingException', 'ServiceUnavailableException', 'ModelStreamLimitExceededException']:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = initial_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"Service capacity reached. Retrying in {delay} seconds...\")\n",
    "                    print(f\"Error: {error}\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Max retries ({max_retries}) reached. Last error: {error}\")\n",
    "                    raise\n",
    "            else:\n",
    "                print(f\"Unhandled error occurred: {error}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = initial_delay * (2 ** attempt)\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "try:\n",
    "    # Invoke model with retry logic\n",
    "    result = invoke_model_with_retry(prompt_data)\n",
    "    # Print the raw result\n",
    "    if result:\n",
    "        print(result.strip())\n",
    "    else:\n",
    "        print(\"No response generated from the model.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to get response after all retries: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロンプトの質問では、モデルは現実的な回答を提供できません。\n",
    "\n",
    "生成 AI モデルが特定の車種に有効な指示に基づいて回答を提供するために、プロンプトの一部として追加の知識ベースを提供することで、モデルの知識をオンザフライで拡張できます。\n",
    "\n",
    "これを使用してアプリケーションを改善する方法を見てみましょう。\n",
    "\n",
    "以下は、AnyCompany AC8 のマニュアルからの抜粋であると仮定します (実際に実在するマニュアルではありませんが、そのように扱います)。 このドキュメントは、Titan Large コンテキスト ウィンドウに完全に収まるほど短く便利です。\n",
    "\n",
    "```plain\n",
    "タイヤとタイヤの空気圧:\n",
    "\n",
    "タイヤは黒いゴムでできており、車のホイールに取り付けられています。タイヤは、運転、コーナリング、ブレーキングに必要なグリップを提供します。考慮すべき 2 つの重要な要素は、タイヤの空気圧とタイヤの摩耗です。これらは、車の性能とハンドリングに影響を与える可能性があります。\n",
    "\n",
    "推奨タイヤ空気圧の確認場所:\n",
    "\n",
    "推奨タイヤ空気圧の仕様は、車の運転席側 B ピラーにある空気圧ラベルに記載されています。または、車のマニュアルを参照してこの情報を入手することもできます。推奨タイヤ空気圧は、速度、乗員数、または車内の最大荷重によって異なる場合があります。\n",
    "\n",
    "タイヤの空気圧の調整:\n",
    "\n",
    "タイヤ空気圧を確認するときは、タイヤが冷えているときに行うことが重要です。つまり、車を少なくとも 3 時間放置して、タイヤが周囲温度と同じ温度になるようにします。\n",
    "\n",
    "タイヤの空気圧を調整するには:\n",
    "\n",
    "車の推奨タイヤ空気圧を確認します。\n",
    "\n",
    "エアポンプの指示に従って、タイヤを適切な空気圧に調整します。\n",
    "車両のセンターディスプレイで、「車の状態」アプリを開きます。\n",
    "「タイヤ空気圧」タブに移動します。\n",
    "「空気圧の調整」オプションを押して、アクションを確認します。\n",
    "タイヤ空気圧を調整するには、30 km/h 以上の速度で車を数分間運転します。\n",
    "\n",
    "注: 場合によっては、タイヤ空気圧に関する警告記号やメッセージを消すために 15 分以上運転する必要があることがあります。警告が消えない場合は、タイヤを冷ましてから上記の手順を繰り返します。\n",
    "\n",
    "パンク:\n",
    "\n",
    "運転中にタイヤがパンクした場合は、タイヤモビリティキットを使用して一時的にパンクを塞ぎ、タイヤを再び膨らませることができます。このキットは通常、車両の荷物スペースの裏地の下に保管されています。\n",
    "\n",
    "タイヤモビリティキットの使用手順:\n",
    "\n",
    "車両のテールゲートまたはトランクを開きます。\n",
    "荷物スペースの裏地を持ち上げて、タイヤモビリティキットにアクセスします。\n",
    "タイヤモビリティキットに付属の説明書に従って、タイヤのパンクを塞ぎます。\n",
    "キットを使用した後は、必ず元の場所にしっかりと戻してください。\n",
    "使用済みのシーラントボトルの廃棄と交換については、AnyCompany または適切なサービスにお問い合わせください。\n",
    "\n",
    "タイヤ モビリティ キットは一時的な解決策であり、最高時速 80 km/h で最大 10 分または 8 km (いずれか早い方) 走行できるように設計されていることに注意してください。パンクしたタイヤはできるだけ早く交換するか、専門家に修理してもらうことをお勧めします。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"タイヤとタイヤの空気圧:\n",
    "\n",
    "タイヤは黒いゴムでできており、車のホイールに取り付けられています。タイヤは、運転、コーナリング、ブレーキングに必要なグリップを提供します。考慮すべき 2 つの重要な要素は、タイヤの空気圧とタイヤの摩耗です。これらは、車の性能とハンドリングに影響を与える可能性があります。\n",
    "\n",
    "推奨タイヤ空気圧の確認場所:\n",
    "\n",
    "推奨タイヤ空気圧の仕様は、車の運転席側 B ピラーにある空気圧ラベルに記載されています。または、車のマニュアルを参照してこの情報を入手することもできます。推奨タイヤ空気圧は、速度、乗員数、または車内の最大荷重によって異なる場合があります。\n",
    "\n",
    "タイヤの空気圧の調整:\n",
    "\n",
    "タイヤ空気圧を確認するときは、タイヤが冷えているときに行うことが重要です。つまり、車を少なくとも 3 時間放置して、タイヤが周囲温度と同じ温度になるようにします。\n",
    "\n",
    "タイヤの空気圧を調整するには:\n",
    "\n",
    "車の推奨タイヤ空気圧を確認します。\n",
    "\n",
    "エアポンプの指示に従って、タイヤを適切な空気圧に調整します。\n",
    "車両のセンターディスプレイで、「車の状態」アプリを開きます。\n",
    "「タイヤ空気圧」タブに移動します。\n",
    "「空気圧の調整」オプションを押して、アクションを確認します。\n",
    "タイヤ空気圧を調整するには、30 km/h 以上の速度で車を数分間運転します。\n",
    "\n",
    "注: 場合によっては、タイヤ空気圧に関する警告記号やメッセージを消すために 15 分以上運転する必要があることがあります。警告が消えない場合は、タイヤを冷ましてから上記の手順を繰り返します。\n",
    "\n",
    "パンク:\n",
    "\n",
    "運転中にタイヤがパンクした場合は、タイヤモビリティキットを使用して一時的にパンクを塞ぎ、タイヤを再び膨らませることができます。このキットは通常、車両の荷物スペースの裏地の下に保管されています。\n",
    "\n",
    "タイヤモビリティキットの使用手順:\n",
    "\n",
    "車両のテールゲートまたはトランクを開きます。\n",
    "荷物スペースの裏地を持ち上げて、タイヤモビリティキットにアクセスします。\n",
    "タイヤモビリティキットに付属の説明書に従って、タイヤのパンクを塞ぎます。\n",
    "キットを使用した後は、必ず元の場所にしっかりと戻してください。\n",
    "使用済みのシーラントボトルの廃棄と交換については、AnyCompany または適切なサービスにお問い合わせください。\n",
    "\n",
    "タイヤ モビリティ キットは一時的な解決策であり、最高時速 80 km/h で最大 10 分または 8 km (いずれか早い方) 走行できるように設計されていることに注意してください。パンクしたタイヤはできるだけ早く交換するか、専門家に修理してもらうことをお勧めします。\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ここで、抜粋全体を質問とともにモデルに渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \" AnyCompany AC8 のパンクしたタイヤを修理するにはどうすればいいですか？\"\n",
    "prompt_data = f\"\"\"## の間に提供された情報のみに基づいて質問に答え、ステップバイステップのガイドを提供します。\n",
    "#\n",
    "{context}\n",
    "#\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 3.4: boto3 経由でモデルを呼び出してレスポンスを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def invoke_llama_with_retry(prompt_data, max_retries=5, initial_delay=10):\n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"messages\": [\n",
    "         {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt_data}],\n",
    "         }\n",
    "        ],\n",
    "    })\n",
    "    modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_client.invoke_model(\n",
    "                body=body, \n",
    "                modelId=modelId, \n",
    "                accept=accept, \n",
    "                contentType=contentType\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "            return response_body[\"content\"][0][\"text\"]\n",
    "\n",
    "        except ClientError as error:\n",
    "            error_code = error.response['Error']['Code']\n",
    "            \n",
    "            if error_code == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources:\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "                raise\n",
    "            \n",
    "            elif error_code in ['ThrottlingException', 'ServiceUnavailableException', 'ModelStreamLimitExceededException']:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = initial_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"Service capacity reached. Retrying in {delay} seconds...\")\n",
    "                    print(f\"Error: {error}\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Max retries ({max_retries}) reached. Last error: {error}\")\n",
    "                    raise\n",
    "            else:\n",
    "                print(f\"Unhandled error occurred: {error}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = initial_delay * (2 ** attempt)\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Failed after {max_retries} attempts. Last error: {e}\")\n",
    "                raise\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    answer = invoke_llama_with_retry(prompt_data)\n",
    "    print(answer.strip())\n",
    "except Exception as e:\n",
    "    print(f\"Final error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルがコンテキストを理解して適切な回答を生成するのに時間がかかるため、応答を数秒間待たなければならなくなり、ユーザーエクスペリエンスが低下する可能性があります。\n",
    "\n",
    "Bedrock は、モデルがトークンを生成するとサービスが出力を生成するストリーミング機能もサポートしています。これを実装する方法の例を次に示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown,Markdown,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def invoke_llama_stream_with_retry(prompt_data, max_retries=5, initial_delay=10):\n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"messages\": [\n",
    "         {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt_data}],\n",
    "         }\n",
    "        ],\n",
    "    })\n",
    "    modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    \n",
    "    print(f\"Using model: {modelId}\")\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_client.invoke_model_with_response_stream(\n",
    "                body=body, \n",
    "                modelId=modelId, \n",
    "                accept=accept, \n",
    "                contentType=contentType\n",
    "            )\n",
    "            \n",
    "            stream = response.get('body')\n",
    "            output = []\n",
    "            i = 1\n",
    "            \n",
    "            if stream:\n",
    "                for event in stream:\n",
    "                    chunk = event.get('chunk')\n",
    "                    if chunk:\n",
    "                       chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                       if chunk_obj[\"type\"] == \"content_block_delta\":\n",
    "                          text = chunk_obj[\"delta\"].get(\"text\", \"\")\n",
    "                          clear_output(wait=True)\n",
    "                          output.append(text)\n",
    "                          display_markdown(Markdown(''.join(output)))\n",
    "                          i += 1\n",
    "                return ''.join(output)  # Return the complete output\n",
    "            else:\n",
    "                raise Exception(\"No stream data received\")\n",
    "\n",
    "        except ClientError as error:\n",
    "            error_code = error.response['Error']['Code']\n",
    "            \n",
    "            if error_code == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources:\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "                raise\n",
    "            \n",
    "            elif error_code in ['ThrottlingException', 'ServiceUnavailableException', 'ModelStreamLimitExceededException']:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = initial_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"Service capacity reached. Retrying in {delay} seconds...\")\n",
    "                    print(f\"Error: {error}\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Max retries ({max_retries}) reached. Last error: {error}\")\n",
    "                    raise\n",
    "            else:\n",
    "                print(f\"Unhandled error occurred: {error}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = initial_delay * (2 ** attempt)\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Failed after {max_retries} attempts. Last error: {e}\")\n",
    "                raise\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    # You can adjust retry parameters here\n",
    "    result = invoke_llama_stream_with_retry(\n",
    "        prompt_data,\n",
    "        max_retries=5,\n",
    "        initial_delay=10\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Final error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "応答には、タイヤの交換方法に関する要約された手順が示されています。\n",
    "\n",
    "これで、検索拡張生成 (RAG) または拡張プロセスを活用して、提供された特定のコンテキストと情報に合わせて調整された応答を生成する方法を学習しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 試してみましょう\n",
    "- 特定のユースケースに合わせてプロンプトを変更し、さまざまなモデルの出力を評価します。\n",
    "- トークンの長さを変えることで、サービスのレイテンシと応答性がどのように変化するかを理解します。\n",
    "- さまざまなプロンプトエンジニアリングの原則を適用して、より良い出力を取得します。\n",
    "\n",
    "### クリーンアップ\n",
    "\n",
    "あなたはこのノートブックを完了しました。ラボの次のパートに移るには、下記を実行してください。:\n",
    "\n",
    "- このノートブックファイルを閉じ、**タスク 4** に進んでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:641467148081:studio-lifecycle-config/lcc-kernel"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
